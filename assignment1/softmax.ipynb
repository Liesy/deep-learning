{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. \n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ],
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from utils.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'utils/cifar-10-batches-py'\n",
    "    \n",
    "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "    try:\n",
    "       del X_train, y_train\n",
    "       del X_test, y_test\n",
    "       print('Clear previously loaded data.')\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **sducs2019/classifiers/softmax.py**. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file sducs2019/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from utils.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss: 2.328663\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$\n",
    "\n",
    "因为权重矩阵随机，意味着最终给10个类的分数是不准确的，即正确分类所对应的得分会很低，经过exp处理后即其概率接近于0"
   ],
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from utils.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numerical: -2.600756 analytic: -2.600756, relative error: 1.050767e-08\n",
      "numerical: -0.490167 analytic: -0.490167, relative error: 9.662303e-08\n",
      "numerical: 0.435567 analytic: 0.435567, relative error: 7.108456e-08\n",
      "numerical: -2.518289 analytic: -2.518289, relative error: 2.101246e-08\n",
      "numerical: -1.253805 analytic: -1.253805, relative error: 6.057823e-08\n",
      "numerical: 0.609091 analytic: 0.609091, relative error: 8.749140e-11\n",
      "numerical: -1.147421 analytic: -1.147421, relative error: 2.770445e-08\n",
      "numerical: -1.575421 analytic: -1.575421, relative error: 3.374973e-09\n",
      "numerical: 0.226663 analytic: 0.226663, relative error: 2.744093e-07\n",
      "numerical: -1.604570 analytic: -1.604570, relative error: 8.859934e-09\n",
      "numerical: -1.376419 analytic: -1.376419, relative error: 3.186058e-09\n",
      "numerical: -4.064373 analytic: -4.064373, relative error: 6.774536e-09\n",
      "numerical: 5.305762 analytic: 5.305762, relative error: 2.144101e-09\n",
      "numerical: -0.984747 analytic: -0.984747, relative error: 3.259262e-08\n",
      "numerical: 1.117531 analytic: 1.117531, relative error: 4.704882e-08\n",
      "numerical: 1.333034 analytic: 1.333034, relative error: 3.787766e-08\n",
      "numerical: 1.888425 analytic: 1.888425, relative error: 4.120960e-09\n",
      "numerical: -5.118527 analytic: -5.118527, relative error: 1.395593e-10\n",
      "numerical: 0.412165 analytic: 0.412165, relative error: 9.922440e-08\n",
      "numerical: 0.352920 analytic: 0.352920, relative error: 4.872612e-08\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from utils.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "naive loss: 2.328663e+00 computed in 0.229519s\n",
      "vectorized loss: 2.328663e+00 computed in 0.003373s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from utils.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        softmax_classifier = Softmax()\n",
    "        softmax_classifier.train(X_train, y_train, learning_rate=lr, reg=reg, num_iters=1500, verbose=True)\n",
    "\n",
    "        y_pred_train = softmax_classifier.predict(X_train)\n",
    "        train_acc = np.mean(y_pred_train == y_train)\n",
    "\n",
    "        y_pred_val = softmax_classifier.predict(X_val)\n",
    "        val_acc = np.mean(y_pred_val == y_val)\n",
    "\n",
    "        results[(lr, reg)] = train_acc, val_acc\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_softmax = softmax_classifier\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 0/1500 : loss = 773.380575\n",
      "iteration 10/1500 : loss = 698.694733\n",
      "iteration 20/1500 : loss = 632.572317\n",
      "iteration 30/1500 : loss = 572.013120\n",
      "iteration 40/1500 : loss = 517.380171\n",
      "iteration 50/1500 : loss = 467.966475\n",
      "iteration 60/1500 : loss = 423.419109\n",
      "iteration 70/1500 : loss = 383.153543\n",
      "iteration 80/1500 : loss = 347.006539\n",
      "iteration 90/1500 : loss = 313.824594\n",
      "iteration 100/1500 : loss = 283.887107\n",
      "iteration 110/1500 : loss = 256.775642\n",
      "iteration 120/1500 : loss = 232.526181\n",
      "iteration 130/1500 : loss = 210.637163\n",
      "iteration 140/1500 : loss = 190.587090\n",
      "iteration 150/1500 : loss = 172.590652\n",
      "iteration 160/1500 : loss = 156.075638\n",
      "iteration 170/1500 : loss = 141.363283\n",
      "iteration 180/1500 : loss = 128.207151\n",
      "iteration 190/1500 : loss = 115.903770\n",
      "iteration 200/1500 : loss = 105.184564\n",
      "iteration 210/1500 : loss = 95.125813\n",
      "iteration 220/1500 : loss = 86.364797\n",
      "iteration 230/1500 : loss = 78.459590\n",
      "iteration 240/1500 : loss = 71.048266\n",
      "iteration 250/1500 : loss = 64.352731\n",
      "iteration 260/1500 : loss = 58.570272\n",
      "iteration 270/1500 : loss = 52.968121\n",
      "iteration 280/1500 : loss = 48.220057\n",
      "iteration 290/1500 : loss = 43.838253\n",
      "iteration 300/1500 : loss = 39.815043\n",
      "iteration 310/1500 : loss = 36.195710\n",
      "iteration 320/1500 : loss = 32.893596\n",
      "iteration 330/1500 : loss = 30.075058\n",
      "iteration 340/1500 : loss = 27.297125\n",
      "iteration 350/1500 : loss = 24.942338\n",
      "iteration 360/1500 : loss = 22.742771\n",
      "iteration 370/1500 : loss = 20.804014\n",
      "iteration 380/1500 : loss = 18.960291\n",
      "iteration 390/1500 : loss = 17.351693\n",
      "iteration 400/1500 : loss = 15.901164\n",
      "iteration 410/1500 : loss = 14.530989\n",
      "iteration 420/1500 : loss = 13.390086\n",
      "iteration 430/1500 : loss = 12.397156\n",
      "iteration 440/1500 : loss = 11.280950\n",
      "iteration 450/1500 : loss = 10.415688\n",
      "iteration 460/1500 : loss = 9.742342\n",
      "iteration 470/1500 : loss = 8.942526\n",
      "iteration 480/1500 : loss = 8.163368\n",
      "iteration 490/1500 : loss = 7.722416\n",
      "iteration 500/1500 : loss = 7.154826\n",
      "iteration 510/1500 : loss = 6.713399\n",
      "iteration 520/1500 : loss = 6.262031\n",
      "iteration 530/1500 : loss = 5.884029\n",
      "iteration 540/1500 : loss = 5.480044\n",
      "iteration 550/1500 : loss = 5.100762\n",
      "iteration 560/1500 : loss = 4.867191\n",
      "iteration 570/1500 : loss = 4.580162\n",
      "iteration 580/1500 : loss = 4.338818\n",
      "iteration 590/1500 : loss = 4.191536\n",
      "iteration 600/1500 : loss = 3.943057\n",
      "iteration 610/1500 : loss = 3.796510\n",
      "iteration 620/1500 : loss = 3.567630\n",
      "iteration 630/1500 : loss = 3.448920\n",
      "iteration 640/1500 : loss = 3.363145\n",
      "iteration 650/1500 : loss = 3.128965\n",
      "iteration 660/1500 : loss = 3.045990\n",
      "iteration 670/1500 : loss = 2.984469\n",
      "iteration 680/1500 : loss = 2.926946\n",
      "iteration 690/1500 : loss = 2.767374\n",
      "iteration 700/1500 : loss = 2.789559\n",
      "iteration 710/1500 : loss = 2.741350\n",
      "iteration 720/1500 : loss = 2.597923\n",
      "iteration 730/1500 : loss = 2.590200\n",
      "iteration 740/1500 : loss = 2.433040\n",
      "iteration 750/1500 : loss = 2.482115\n",
      "iteration 760/1500 : loss = 2.401696\n",
      "iteration 770/1500 : loss = 2.393507\n",
      "iteration 780/1500 : loss = 2.348224\n",
      "iteration 790/1500 : loss = 2.378609\n",
      "iteration 800/1500 : loss = 2.396356\n",
      "iteration 810/1500 : loss = 2.289139\n",
      "iteration 820/1500 : loss = 2.341598\n",
      "iteration 830/1500 : loss = 2.294554\n",
      "iteration 840/1500 : loss = 2.295566\n",
      "iteration 850/1500 : loss = 2.166858\n",
      "iteration 860/1500 : loss = 2.225853\n",
      "iteration 870/1500 : loss = 2.221660\n",
      "iteration 880/1500 : loss = 2.166802\n",
      "iteration 890/1500 : loss = 2.220733\n",
      "iteration 900/1500 : loss = 2.242542\n",
      "iteration 910/1500 : loss = 2.119809\n",
      "iteration 920/1500 : loss = 2.159462\n",
      "iteration 930/1500 : loss = 2.247549\n",
      "iteration 940/1500 : loss = 2.173548\n",
      "iteration 950/1500 : loss = 2.130983\n",
      "iteration 960/1500 : loss = 1.990999\n",
      "iteration 970/1500 : loss = 2.186905\n",
      "iteration 980/1500 : loss = 2.137081\n",
      "iteration 990/1500 : loss = 2.142400\n",
      "iteration 1000/1500 : loss = 2.142514\n",
      "iteration 1010/1500 : loss = 2.131013\n",
      "iteration 1020/1500 : loss = 2.067203\n",
      "iteration 1030/1500 : loss = 2.159996\n",
      "iteration 1040/1500 : loss = 2.090082\n",
      "iteration 1050/1500 : loss = 2.099328\n",
      "iteration 1060/1500 : loss = 2.080370\n",
      "iteration 1070/1500 : loss = 2.108044\n",
      "iteration 1080/1500 : loss = 2.136078\n",
      "iteration 1090/1500 : loss = 2.076804\n",
      "iteration 1100/1500 : loss = 2.105272\n",
      "iteration 1110/1500 : loss = 2.053305\n",
      "iteration 1120/1500 : loss = 2.143634\n",
      "iteration 1130/1500 : loss = 2.088727\n",
      "iteration 1140/1500 : loss = 2.113229\n",
      "iteration 1150/1500 : loss = 2.047767\n",
      "iteration 1160/1500 : loss = 2.167055\n",
      "iteration 1170/1500 : loss = 2.049437\n",
      "iteration 1180/1500 : loss = 2.127576\n",
      "iteration 1190/1500 : loss = 2.035780\n",
      "iteration 1200/1500 : loss = 2.141393\n",
      "iteration 1210/1500 : loss = 2.065213\n",
      "iteration 1220/1500 : loss = 2.119368\n",
      "iteration 1230/1500 : loss = 2.084173\n",
      "iteration 1240/1500 : loss = 2.052158\n",
      "iteration 1250/1500 : loss = 2.072443\n",
      "iteration 1260/1500 : loss = 2.022338\n",
      "iteration 1270/1500 : loss = 2.043526\n",
      "iteration 1280/1500 : loss = 2.037363\n",
      "iteration 1290/1500 : loss = 2.070760\n",
      "iteration 1300/1500 : loss = 2.070148\n",
      "iteration 1310/1500 : loss = 2.144531\n",
      "iteration 1320/1500 : loss = 2.068361\n",
      "iteration 1330/1500 : loss = 2.112789\n",
      "iteration 1340/1500 : loss = 2.065949\n",
      "iteration 1350/1500 : loss = 2.112369\n",
      "iteration 1360/1500 : loss = 1.956511\n",
      "iteration 1370/1500 : loss = 2.158784\n",
      "iteration 1380/1500 : loss = 2.124931\n",
      "iteration 1390/1500 : loss = 2.074912\n",
      "iteration 1400/1500 : loss = 2.108449\n",
      "iteration 1410/1500 : loss = 2.108927\n",
      "iteration 1420/1500 : loss = 1.979946\n",
      "iteration 1430/1500 : loss = 2.179479\n",
      "iteration 1440/1500 : loss = 2.135196\n",
      "iteration 1450/1500 : loss = 2.067996\n",
      "iteration 1460/1500 : loss = 2.047056\n",
      "iteration 1470/1500 : loss = 2.046841\n",
      "iteration 1480/1500 : loss = 2.126405\n",
      "iteration 1490/1500 : loss = 2.060006\n",
      "iteration 0/1500 : loss = 1559.303178\n",
      "iteration 10/1500 : loss = 1275.020590\n",
      "iteration 20/1500 : loss = 1042.703904\n",
      "iteration 30/1500 : loss = 853.387310\n",
      "iteration 40/1500 : loss = 697.744406\n",
      "iteration 50/1500 : loss = 571.422836\n",
      "iteration 60/1500 : loss = 467.326206\n",
      "iteration 70/1500 : loss = 382.610440\n",
      "iteration 80/1500 : loss = 313.161025\n",
      "iteration 90/1500 : loss = 256.478637\n",
      "iteration 100/1500 : loss = 210.189538\n",
      "iteration 110/1500 : loss = 172.261492\n",
      "iteration 120/1500 : loss = 141.166625\n",
      "iteration 130/1500 : loss = 115.811535\n",
      "iteration 140/1500 : loss = 95.092736\n",
      "iteration 150/1500 : loss = 78.096491\n",
      "iteration 160/1500 : loss = 64.172566\n",
      "iteration 170/1500 : loss = 52.834410\n",
      "iteration 180/1500 : loss = 43.728442\n",
      "iteration 190/1500 : loss = 36.078137\n",
      "iteration 200/1500 : loss = 29.839550\n",
      "iteration 210/1500 : loss = 24.806681\n",
      "iteration 220/1500 : loss = 20.810073\n",
      "iteration 230/1500 : loss = 17.393615\n",
      "iteration 240/1500 : loss = 14.617150\n",
      "iteration 250/1500 : loss = 12.283748\n",
      "iteration 260/1500 : loss = 10.445838\n",
      "iteration 270/1500 : loss = 8.955667\n",
      "iteration 280/1500 : loss = 7.676228\n",
      "iteration 290/1500 : loss = 6.739551\n",
      "iteration 300/1500 : loss = 5.860250\n",
      "iteration 310/1500 : loss = 5.209358\n",
      "iteration 320/1500 : loss = 4.685423\n",
      "iteration 330/1500 : loss = 4.170428\n",
      "iteration 340/1500 : loss = 3.780251\n",
      "iteration 350/1500 : loss = 3.485253\n",
      "iteration 360/1500 : loss = 3.157893\n",
      "iteration 370/1500 : loss = 3.036845\n",
      "iteration 380/1500 : loss = 2.871149\n",
      "iteration 390/1500 : loss = 2.719464\n",
      "iteration 400/1500 : loss = 2.609793\n",
      "iteration 410/1500 : loss = 2.546688\n",
      "iteration 420/1500 : loss = 2.527541\n",
      "iteration 430/1500 : loss = 2.383432\n",
      "iteration 440/1500 : loss = 2.385620\n",
      "iteration 450/1500 : loss = 2.313949\n",
      "iteration 460/1500 : loss = 2.281746\n",
      "iteration 470/1500 : loss = 2.253215\n",
      "iteration 480/1500 : loss = 2.280063\n",
      "iteration 490/1500 : loss = 2.256289\n",
      "iteration 500/1500 : loss = 2.216825\n",
      "iteration 510/1500 : loss = 2.167424\n",
      "iteration 520/1500 : loss = 2.167012\n",
      "iteration 530/1500 : loss = 2.169373\n",
      "iteration 540/1500 : loss = 2.242023\n",
      "iteration 550/1500 : loss = 2.145328\n",
      "iteration 560/1500 : loss = 2.216186\n",
      "iteration 570/1500 : loss = 2.130908\n",
      "iteration 580/1500 : loss = 2.154240\n",
      "iteration 590/1500 : loss = 2.170584\n",
      "iteration 600/1500 : loss = 2.205545\n",
      "iteration 610/1500 : loss = 2.122720\n",
      "iteration 620/1500 : loss = 2.154808\n",
      "iteration 630/1500 : loss = 2.168327\n",
      "iteration 640/1500 : loss = 2.138895\n",
      "iteration 650/1500 : loss = 2.174888\n",
      "iteration 660/1500 : loss = 2.143289\n",
      "iteration 670/1500 : loss = 2.159826\n",
      "iteration 680/1500 : loss = 2.076336\n",
      "iteration 690/1500 : loss = 2.109310\n",
      "iteration 700/1500 : loss = 2.198510\n",
      "iteration 710/1500 : loss = 2.056303\n",
      "iteration 720/1500 : loss = 2.160364\n",
      "iteration 730/1500 : loss = 2.171169\n",
      "iteration 740/1500 : loss = 2.182845\n",
      "iteration 750/1500 : loss = 2.138009\n",
      "iteration 760/1500 : loss = 2.172173\n",
      "iteration 770/1500 : loss = 2.134771\n",
      "iteration 780/1500 : loss = 2.047766\n",
      "iteration 790/1500 : loss = 2.095680\n",
      "iteration 800/1500 : loss = 2.113588\n",
      "iteration 810/1500 : loss = 2.205349\n",
      "iteration 820/1500 : loss = 2.149801\n",
      "iteration 830/1500 : loss = 2.146101\n",
      "iteration 840/1500 : loss = 2.182438\n",
      "iteration 850/1500 : loss = 2.155789\n",
      "iteration 860/1500 : loss = 2.120651\n",
      "iteration 870/1500 : loss = 2.180472\n",
      "iteration 880/1500 : loss = 2.167927\n",
      "iteration 890/1500 : loss = 2.079092\n",
      "iteration 900/1500 : loss = 2.120794\n",
      "iteration 910/1500 : loss = 2.148191\n",
      "iteration 920/1500 : loss = 2.173453\n",
      "iteration 930/1500 : loss = 2.185561\n",
      "iteration 940/1500 : loss = 2.153554\n",
      "iteration 950/1500 : loss = 2.190603\n",
      "iteration 960/1500 : loss = 2.119564\n",
      "iteration 970/1500 : loss = 2.149129\n",
      "iteration 980/1500 : loss = 2.172946\n",
      "iteration 990/1500 : loss = 2.096585\n",
      "iteration 1000/1500 : loss = 2.119619\n",
      "iteration 1010/1500 : loss = 2.158259\n",
      "iteration 1020/1500 : loss = 2.123849\n",
      "iteration 1030/1500 : loss = 2.103856\n",
      "iteration 1040/1500 : loss = 2.147336\n",
      "iteration 1050/1500 : loss = 2.152582\n",
      "iteration 1060/1500 : loss = 2.137813\n",
      "iteration 1070/1500 : loss = 2.106829\n",
      "iteration 1080/1500 : loss = 2.146629\n",
      "iteration 1090/1500 : loss = 2.097460\n",
      "iteration 1100/1500 : loss = 2.201630\n",
      "iteration 1110/1500 : loss = 2.127454\n",
      "iteration 1120/1500 : loss = 2.178382\n",
      "iteration 1130/1500 : loss = 2.074148\n",
      "iteration 1140/1500 : loss = 2.092864\n",
      "iteration 1150/1500 : loss = 2.218295\n",
      "iteration 1160/1500 : loss = 2.098599\n",
      "iteration 1170/1500 : loss = 2.058847\n",
      "iteration 1180/1500 : loss = 2.176118\n",
      "iteration 1190/1500 : loss = 2.113048\n",
      "iteration 1200/1500 : loss = 2.062202\n",
      "iteration 1210/1500 : loss = 2.164421\n",
      "iteration 1220/1500 : loss = 2.129291\n",
      "iteration 1230/1500 : loss = 2.183547\n",
      "iteration 1240/1500 : loss = 2.098138\n",
      "iteration 1250/1500 : loss = 2.108615\n",
      "iteration 1260/1500 : loss = 2.085619\n",
      "iteration 1270/1500 : loss = 2.190422\n",
      "iteration 1280/1500 : loss = 2.171351\n",
      "iteration 1290/1500 : loss = 2.131939\n",
      "iteration 1300/1500 : loss = 2.182551\n",
      "iteration 1310/1500 : loss = 2.119380\n",
      "iteration 1320/1500 : loss = 2.135175\n",
      "iteration 1330/1500 : loss = 2.142981\n",
      "iteration 1340/1500 : loss = 2.210911\n",
      "iteration 1350/1500 : loss = 2.128710\n",
      "iteration 1360/1500 : loss = 2.067190\n",
      "iteration 1370/1500 : loss = 2.075574\n",
      "iteration 1380/1500 : loss = 2.138315\n",
      "iteration 1390/1500 : loss = 2.143765\n",
      "iteration 1400/1500 : loss = 2.119405\n",
      "iteration 1410/1500 : loss = 2.130356\n",
      "iteration 1420/1500 : loss = 2.153621\n",
      "iteration 1430/1500 : loss = 2.119416\n",
      "iteration 1440/1500 : loss = 2.241787\n",
      "iteration 1450/1500 : loss = 2.112289\n",
      "iteration 1460/1500 : loss = 2.145341\n",
      "iteration 1470/1500 : loss = 2.172544\n",
      "iteration 1480/1500 : loss = 2.140396\n",
      "iteration 1490/1500 : loss = 2.094040\n",
      "iteration 0/1500 : loss = 783.112157\n",
      "iteration 10/1500 : loss = 472.158786\n",
      "iteration 20/1500 : loss = 285.167543\n",
      "iteration 30/1500 : loss = 172.351626\n",
      "iteration 40/1500 : loss = 104.501348\n",
      "iteration 50/1500 : loss = 63.811145\n",
      "iteration 60/1500 : loss = 39.291348\n",
      "iteration 70/1500 : loss = 24.412530\n",
      "iteration 80/1500 : loss = 15.565897\n",
      "iteration 90/1500 : loss = 10.220237\n",
      "iteration 100/1500 : loss = 6.912546\n",
      "iteration 110/1500 : loss = 4.970026\n",
      "iteration 120/1500 : loss = 3.828922\n",
      "iteration 130/1500 : loss = 3.055931\n",
      "iteration 140/1500 : loss = 2.684818\n",
      "iteration 150/1500 : loss = 2.500268\n",
      "iteration 160/1500 : loss = 2.316121\n",
      "iteration 170/1500 : loss = 2.217873\n",
      "iteration 180/1500 : loss = 2.269620\n",
      "iteration 190/1500 : loss = 2.194365\n",
      "iteration 200/1500 : loss = 2.103072\n",
      "iteration 210/1500 : loss = 2.113580\n",
      "iteration 220/1500 : loss = 2.005419\n",
      "iteration 230/1500 : loss = 2.086409\n",
      "iteration 240/1500 : loss = 2.141905\n",
      "iteration 250/1500 : loss = 2.142667\n",
      "iteration 260/1500 : loss = 2.099681\n",
      "iteration 270/1500 : loss = 2.124118\n",
      "iteration 280/1500 : loss = 1.984355\n",
      "iteration 290/1500 : loss = 2.191415\n",
      "iteration 300/1500 : loss = 2.023717\n",
      "iteration 310/1500 : loss = 2.087127\n",
      "iteration 320/1500 : loss = 2.120128\n",
      "iteration 330/1500 : loss = 2.038213\n",
      "iteration 340/1500 : loss = 1.986964\n",
      "iteration 350/1500 : loss = 2.125875\n",
      "iteration 360/1500 : loss = 2.128942\n",
      "iteration 370/1500 : loss = 2.095328\n",
      "iteration 380/1500 : loss = 2.138730\n",
      "iteration 390/1500 : loss = 2.092391\n",
      "iteration 400/1500 : loss = 2.104889\n",
      "iteration 410/1500 : loss = 2.148445\n",
      "iteration 420/1500 : loss = 2.039265\n",
      "iteration 430/1500 : loss = 2.114852\n",
      "iteration 440/1500 : loss = 2.001142\n",
      "iteration 450/1500 : loss = 2.054352\n",
      "iteration 460/1500 : loss = 2.100139\n",
      "iteration 470/1500 : loss = 2.099687\n",
      "iteration 480/1500 : loss = 1.989604\n",
      "iteration 490/1500 : loss = 2.054496\n",
      "iteration 500/1500 : loss = 2.086535\n",
      "iteration 510/1500 : loss = 2.076821\n",
      "iteration 520/1500 : loss = 2.056222\n",
      "iteration 530/1500 : loss = 2.169001\n",
      "iteration 540/1500 : loss = 2.171460\n",
      "iteration 550/1500 : loss = 2.100290\n",
      "iteration 560/1500 : loss = 2.059602\n",
      "iteration 570/1500 : loss = 2.150613\n",
      "iteration 580/1500 : loss = 2.094072\n",
      "iteration 590/1500 : loss = 2.123830\n",
      "iteration 600/1500 : loss = 2.141059\n",
      "iteration 610/1500 : loss = 2.163045\n",
      "iteration 620/1500 : loss = 2.188312\n",
      "iteration 630/1500 : loss = 2.128230\n",
      "iteration 640/1500 : loss = 2.027427\n",
      "iteration 650/1500 : loss = 2.186228\n",
      "iteration 660/1500 : loss = 2.066028\n",
      "iteration 670/1500 : loss = 2.150503\n",
      "iteration 680/1500 : loss = 2.122178\n",
      "iteration 690/1500 : loss = 2.104060\n",
      "iteration 700/1500 : loss = 2.131744\n",
      "iteration 710/1500 : loss = 2.066491\n",
      "iteration 720/1500 : loss = 2.078470\n",
      "iteration 730/1500 : loss = 2.068521\n",
      "iteration 740/1500 : loss = 2.085734\n",
      "iteration 750/1500 : loss = 2.073605\n",
      "iteration 760/1500 : loss = 2.126512\n",
      "iteration 770/1500 : loss = 2.098050\n",
      "iteration 780/1500 : loss = 2.083358\n",
      "iteration 790/1500 : loss = 2.141811\n",
      "iteration 800/1500 : loss = 2.087930\n",
      "iteration 810/1500 : loss = 2.149263\n",
      "iteration 820/1500 : loss = 2.049269\n",
      "iteration 830/1500 : loss = 2.071601\n",
      "iteration 840/1500 : loss = 2.108541\n",
      "iteration 850/1500 : loss = 2.117678\n",
      "iteration 860/1500 : loss = 2.135399\n",
      "iteration 870/1500 : loss = 2.076941\n",
      "iteration 880/1500 : loss = 2.126480\n",
      "iteration 890/1500 : loss = 1.947639\n",
      "iteration 900/1500 : loss = 2.094900\n",
      "iteration 910/1500 : loss = 2.103354\n",
      "iteration 920/1500 : loss = 2.124554\n",
      "iteration 930/1500 : loss = 2.193716\n",
      "iteration 940/1500 : loss = 1.981854\n",
      "iteration 950/1500 : loss = 2.147086\n",
      "iteration 960/1500 : loss = 2.060572\n",
      "iteration 970/1500 : loss = 2.117513\n",
      "iteration 980/1500 : loss = 2.078525\n",
      "iteration 990/1500 : loss = 2.179359\n",
      "iteration 1000/1500 : loss = 2.144608\n",
      "iteration 1010/1500 : loss = 2.061675\n",
      "iteration 1020/1500 : loss = 2.156363\n",
      "iteration 1030/1500 : loss = 2.125238\n",
      "iteration 1040/1500 : loss = 2.088814\n",
      "iteration 1050/1500 : loss = 2.019618\n",
      "iteration 1060/1500 : loss = 2.111531\n",
      "iteration 1070/1500 : loss = 2.045698\n",
      "iteration 1080/1500 : loss = 2.157143\n",
      "iteration 1090/1500 : loss = 2.147153\n",
      "iteration 1100/1500 : loss = 2.109601\n",
      "iteration 1110/1500 : loss = 2.061457\n",
      "iteration 1120/1500 : loss = 2.087956\n",
      "iteration 1130/1500 : loss = 2.098809\n",
      "iteration 1140/1500 : loss = 2.067175\n",
      "iteration 1150/1500 : loss = 2.045662\n",
      "iteration 1160/1500 : loss = 2.109037\n",
      "iteration 1170/1500 : loss = 2.071598\n",
      "iteration 1180/1500 : loss = 2.054696\n",
      "iteration 1190/1500 : loss = 2.086139\n",
      "iteration 1200/1500 : loss = 2.084971\n",
      "iteration 1210/1500 : loss = 2.099827\n",
      "iteration 1220/1500 : loss = 1.992846\n",
      "iteration 1230/1500 : loss = 2.153709\n",
      "iteration 1240/1500 : loss = 2.173189\n",
      "iteration 1250/1500 : loss = 2.173213\n",
      "iteration 1260/1500 : loss = 2.124466\n",
      "iteration 1270/1500 : loss = 2.112440\n",
      "iteration 1280/1500 : loss = 2.223980\n",
      "iteration 1290/1500 : loss = 2.161442\n",
      "iteration 1300/1500 : loss = 2.125512\n",
      "iteration 1310/1500 : loss = 2.112204\n",
      "iteration 1320/1500 : loss = 2.053973\n",
      "iteration 1330/1500 : loss = 2.114574\n",
      "iteration 1340/1500 : loss = 2.092628\n",
      "iteration 1350/1500 : loss = 2.094806\n",
      "iteration 1360/1500 : loss = 2.028724\n",
      "iteration 1370/1500 : loss = 2.100601\n",
      "iteration 1380/1500 : loss = 2.075538\n",
      "iteration 1390/1500 : loss = 2.168930\n",
      "iteration 1400/1500 : loss = 2.154725\n",
      "iteration 1410/1500 : loss = 2.103407\n",
      "iteration 1420/1500 : loss = 2.114605\n",
      "iteration 1430/1500 : loss = 2.142357\n",
      "iteration 1440/1500 : loss = 2.092964\n",
      "iteration 1450/1500 : loss = 2.055469\n",
      "iteration 1460/1500 : loss = 2.130509\n",
      "iteration 1470/1500 : loss = 2.011059\n",
      "iteration 1480/1500 : loss = 2.001123\n",
      "iteration 1490/1500 : loss = 2.101677\n",
      "iteration 0/1500 : loss = 1550.058096\n",
      "iteration 10/1500 : loss = 555.741176\n",
      "iteration 20/1500 : loss = 200.368218\n",
      "iteration 30/1500 : loss = 73.230959\n",
      "iteration 40/1500 : loss = 27.481613\n",
      "iteration 50/1500 : loss = 11.224755\n",
      "iteration 60/1500 : loss = 5.412308\n",
      "iteration 70/1500 : loss = 3.334697\n",
      "iteration 80/1500 : loss = 2.653897\n",
      "iteration 90/1500 : loss = 2.372249\n",
      "iteration 100/1500 : loss = 2.158941\n",
      "iteration 110/1500 : loss = 2.113757\n",
      "iteration 120/1500 : loss = 2.163768\n",
      "iteration 130/1500 : loss = 2.211436\n",
      "iteration 140/1500 : loss = 2.187775\n",
      "iteration 150/1500 : loss = 2.127633\n",
      "iteration 160/1500 : loss = 2.149488\n",
      "iteration 170/1500 : loss = 2.159450\n",
      "iteration 180/1500 : loss = 2.128102\n",
      "iteration 190/1500 : loss = 2.113251\n",
      "iteration 200/1500 : loss = 2.208652\n",
      "iteration 210/1500 : loss = 2.096537\n",
      "iteration 220/1500 : loss = 2.149410\n",
      "iteration 230/1500 : loss = 2.218627\n",
      "iteration 240/1500 : loss = 2.140796\n",
      "iteration 250/1500 : loss = 2.133281\n",
      "iteration 260/1500 : loss = 2.118677\n",
      "iteration 270/1500 : loss = 2.183668\n",
      "iteration 280/1500 : loss = 2.240888\n",
      "iteration 290/1500 : loss = 2.132053\n",
      "iteration 300/1500 : loss = 2.190658\n",
      "iteration 310/1500 : loss = 2.135840\n",
      "iteration 320/1500 : loss = 2.151318\n",
      "iteration 330/1500 : loss = 2.172713\n",
      "iteration 340/1500 : loss = 2.157809\n",
      "iteration 350/1500 : loss = 2.136713\n",
      "iteration 360/1500 : loss = 2.062809\n",
      "iteration 370/1500 : loss = 2.140790\n",
      "iteration 380/1500 : loss = 2.068842\n",
      "iteration 390/1500 : loss = 2.223756\n",
      "iteration 400/1500 : loss = 2.165687\n",
      "iteration 410/1500 : loss = 2.130916\n",
      "iteration 420/1500 : loss = 2.124189\n",
      "iteration 430/1500 : loss = 2.154266\n",
      "iteration 440/1500 : loss = 2.213363\n",
      "iteration 450/1500 : loss = 2.164255\n",
      "iteration 460/1500 : loss = 2.133832\n",
      "iteration 470/1500 : loss = 2.106943\n",
      "iteration 480/1500 : loss = 2.097750\n",
      "iteration 490/1500 : loss = 2.183584\n",
      "iteration 500/1500 : loss = 2.122576\n",
      "iteration 510/1500 : loss = 2.165459\n",
      "iteration 520/1500 : loss = 2.150080\n",
      "iteration 530/1500 : loss = 2.071235\n",
      "iteration 540/1500 : loss = 2.094594\n",
      "iteration 550/1500 : loss = 2.187598\n",
      "iteration 560/1500 : loss = 2.148776\n",
      "iteration 570/1500 : loss = 2.234030\n",
      "iteration 580/1500 : loss = 2.193141\n",
      "iteration 590/1500 : loss = 2.103495\n",
      "iteration 600/1500 : loss = 2.057384\n",
      "iteration 610/1500 : loss = 2.120230\n",
      "iteration 620/1500 : loss = 2.119444\n",
      "iteration 630/1500 : loss = 2.220529\n",
      "iteration 640/1500 : loss = 2.150159\n",
      "iteration 650/1500 : loss = 2.138449\n",
      "iteration 660/1500 : loss = 2.200077\n",
      "iteration 670/1500 : loss = 2.196428\n",
      "iteration 680/1500 : loss = 2.184588\n",
      "iteration 690/1500 : loss = 2.221407\n",
      "iteration 700/1500 : loss = 2.152656\n",
      "iteration 710/1500 : loss = 2.189868\n",
      "iteration 720/1500 : loss = 2.122056\n",
      "iteration 730/1500 : loss = 2.161946\n",
      "iteration 740/1500 : loss = 2.174809\n",
      "iteration 750/1500 : loss = 2.190842\n",
      "iteration 760/1500 : loss = 2.082060\n",
      "iteration 770/1500 : loss = 2.085278\n",
      "iteration 780/1500 : loss = 2.131241\n",
      "iteration 790/1500 : loss = 2.220516\n",
      "iteration 800/1500 : loss = 2.183985\n",
      "iteration 810/1500 : loss = 2.105500\n",
      "iteration 820/1500 : loss = 2.144153\n",
      "iteration 830/1500 : loss = 2.212489\n",
      "iteration 840/1500 : loss = 2.070002\n",
      "iteration 850/1500 : loss = 2.156795\n",
      "iteration 860/1500 : loss = 2.137012\n",
      "iteration 870/1500 : loss = 2.203498\n",
      "iteration 880/1500 : loss = 2.147364\n",
      "iteration 890/1500 : loss = 2.129504\n",
      "iteration 900/1500 : loss = 2.162511\n",
      "iteration 910/1500 : loss = 2.175565\n",
      "iteration 920/1500 : loss = 2.126642\n",
      "iteration 930/1500 : loss = 2.206956\n",
      "iteration 940/1500 : loss = 2.128022\n",
      "iteration 950/1500 : loss = 2.187397\n",
      "iteration 960/1500 : loss = 2.181811\n",
      "iteration 970/1500 : loss = 2.164435\n",
      "iteration 980/1500 : loss = 2.240013\n",
      "iteration 990/1500 : loss = 2.159263\n",
      "iteration 1000/1500 : loss = 2.157075\n",
      "iteration 1010/1500 : loss = 2.181232\n",
      "iteration 1020/1500 : loss = 2.161873\n",
      "iteration 1030/1500 : loss = 2.191898\n",
      "iteration 1040/1500 : loss = 2.190685\n",
      "iteration 1050/1500 : loss = 2.178968\n",
      "iteration 1060/1500 : loss = 2.156743\n",
      "iteration 1070/1500 : loss = 2.136388\n",
      "iteration 1080/1500 : loss = 2.099740\n",
      "iteration 1090/1500 : loss = 2.202966\n",
      "iteration 1100/1500 : loss = 2.124660\n",
      "iteration 1110/1500 : loss = 2.132418\n",
      "iteration 1120/1500 : loss = 2.175110\n",
      "iteration 1130/1500 : loss = 2.107138\n",
      "iteration 1140/1500 : loss = 2.160460\n",
      "iteration 1150/1500 : loss = 2.120730\n",
      "iteration 1160/1500 : loss = 2.189268\n",
      "iteration 1170/1500 : loss = 2.100202\n",
      "iteration 1180/1500 : loss = 2.175740\n",
      "iteration 1190/1500 : loss = 2.157475\n",
      "iteration 1200/1500 : loss = 2.157933\n",
      "iteration 1210/1500 : loss = 2.174425\n",
      "iteration 1220/1500 : loss = 2.162917\n",
      "iteration 1230/1500 : loss = 2.178933\n",
      "iteration 1240/1500 : loss = 2.093042\n",
      "iteration 1250/1500 : loss = 2.187171\n",
      "iteration 1260/1500 : loss = 2.176140\n",
      "iteration 1270/1500 : loss = 2.133325\n",
      "iteration 1280/1500 : loss = 2.115323\n",
      "iteration 1290/1500 : loss = 2.138008\n",
      "iteration 1300/1500 : loss = 2.115475\n",
      "iteration 1310/1500 : loss = 2.159735\n",
      "iteration 1320/1500 : loss = 2.104159\n",
      "iteration 1330/1500 : loss = 2.169264\n",
      "iteration 1340/1500 : loss = 2.123902\n",
      "iteration 1350/1500 : loss = 2.087625\n",
      "iteration 1360/1500 : loss = 2.157944\n",
      "iteration 1370/1500 : loss = 2.116066\n",
      "iteration 1380/1500 : loss = 2.124266\n",
      "iteration 1390/1500 : loss = 2.160057\n",
      "iteration 1400/1500 : loss = 2.123465\n",
      "iteration 1410/1500 : loss = 2.150469\n",
      "iteration 1420/1500 : loss = 2.131368\n",
      "iteration 1430/1500 : loss = 2.206420\n",
      "iteration 1440/1500 : loss = 2.166993\n",
      "iteration 1450/1500 : loss = 2.125994\n",
      "iteration 1460/1500 : loss = 2.145067\n",
      "iteration 1470/1500 : loss = 2.238199\n",
      "iteration 1480/1500 : loss = 2.170844\n",
      "iteration 1490/1500 : loss = 2.121446\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.319367 val accuracy: 0.332000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.302408 val accuracy: 0.319000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.318306 val accuracy: 0.333000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.299490 val accuracy: 0.320000\n",
      "best validation accuracy achieved during cross-validation: 0.333000\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "code"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.327000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ 正确\n",
    "\n",
    "\n",
    "$\\color{blue}{\\textit Your Explanation:}$\n",
    "\n",
    "SVM损失函数计算时如果新加入的测试图片分类正确，则loss一定为0；但是对与softmax而言，不论分类是否正确，loss总会是存在的，即使loss趋近于0，但整体而言，损失值变化了。"
   ],
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.2 64-bit ('liyang-env-py3': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "interpreter": {
   "hash": "7dac0ff4b301af5c54bb9e3868361bae9217c7ca3b56b0a231fd4f88ece2400f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}